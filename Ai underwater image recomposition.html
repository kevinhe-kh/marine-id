 <!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Underwater Image Recomposition</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', sans-serif;
        }
        .custom-file-button input[type="file"] {
            display: none;
        }
        #loader {
            border: 5px solid #f3f3f3;
            border-top: 5px solid #3498db;
            border-radius: 50%;
            width: 50px;
            height: 50px;
            animation: spin 1.5s linear infinite;
        }
        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }
    </style>
</head>
<body class="bg-gray-900 text-gray-200 flex flex-col items-center justify-center min-h-screen p-4">

    <div class="w-full max-w-4xl text-center">
        <header class="mb-8">
            <h1 class="text-4xl md:text-5xl font-bold text-cyan-400 mb-2">AI Underwater Recomposition</h1>
            <p class="text-lg text-gray-400">Replacing the subject with an AI-generated version in its true colors.</p>
        </header>

        <!-- File Upload Section -->
        <div class="bg-gray-800 p-6 rounded-xl shadow-lg w-full mb-8">
            <p class="mb-4">Upload an underwater photo taken with natural light.</p>
            <div class="custom-file-button">
                <label for="imageLoader" class="cursor-pointer bg-cyan-600 hover:bg-cyan-700 text-white font-bold py-3 px-6 rounded-lg transition-colors duration-300 inline-block">
                    Select Image
                </label>
                <input type="file" id="imageLoader" name="imageLoader" accept="image/*"/>
            </div>
        </div>

        <!-- Loading & Identification Indicator -->
        <div id="loader-container" class="hidden flex-col items-center justify-center my-8">
            <div id="loader"></div>
        </div>

        <!-- Image Display Area -->
        <div id="image-container" class="grid grid-cols-1 md:grid-cols-2 gap-8 w-full">
            <div id="original-container" class="hidden text-center">
                <img id="original-image" class="rounded-lg shadow-md w-full" alt="Original underwater photo">
                <p id="subject-name-display" class="text-cyan-400 font-semibold mt-2 text-lg h-8"></p>
            </div>
            <div id="corrected-container" class="hidden">
                <canvas id="corrected-canvas" class="rounded-lg shadow-md w-full cursor-pointer hover:opacity-90 transition-opacity"></canvas>
            </div>
        </div>
        
        <!-- Error Message -->
        <div id="error-container" class="hidden mt-4 bg-red-900 border border-red-700 text-red-200 px-4 py-3 rounded-lg relative" role="alert">
            <strong class="font-bold">Error:</strong>
            <span class="block sm:inline" id="error-message"></span>
        </div>
    </div>

    <!-- "Beautiful Shot" Modal -->
    <div id="beautiful-shot-modal" class="fixed inset-0 bg-black bg-opacity-70 hidden items-center justify-center p-4" onclick="this.style.display='none'">
        <div class="bg-gray-800 rounded-xl p-8 text-center shadow-2xl">
            <h2 class="text-3xl font-bold text-green-400 mb-4">Beautiful Shot!</h2>
            <p id="beautiful-shot-text" class="text-gray-300"></p>
            <p class="mt-4 text-sm text-gray-500">(Click anywhere to close)</p>
        </div>
    </div>

    <!-- Lightbox Modal -->
    <div id="lightbox-modal" class="fixed inset-0 bg-black bg-opacity-80 hidden items-center justify-center p-4 z-50">
        <div class="relative bg-gray-900 p-4 rounded-lg shadow-2xl max-w-4xl w-full max-h-[90vh]">
            <img id="lightbox-image" class="w-full h-full object-contain" alt="Enlarged corrected view">
            <div class="mt-4 flex flex-col sm:flex-row justify-center items-center gap-4">
                <a id="download-link" href="#" download="ai-recomposed-photo.png" class="bg-green-600 hover:bg-green-700 text-white font-bold py-2 px-5 rounded-lg transition-colors duration-300 text-center w-full sm:w-auto">Download</a>
                <button id="close-lightbox" class="bg-red-600 hover:bg-red-700 text-white font-bold py-2 px-5 rounded-lg transition-colors duration-300 w-full sm:w-auto">Close</button>
            </div>
        </div>
    </div>

    <script>
        // --- DOM Elements ---
        const imageLoader = document.getElementById('imageLoader');
        const originalImage = document.getElementById('original-image');
        const correctedCanvas = document.getElementById('corrected-canvas');
        const loaderContainer = document.getElementById('loader-container');
        const originalContainer = document.getElementById('original-container');
        const subjectNameDisplay = document.getElementById('subject-name-display');
        const correctedContainer = document.getElementById('corrected-container');
        const errorContainer = document.getElementById('error-container');
        const errorMessage = document.getElementById('error-message');
        const beautifulShotModal = document.getElementById('beautiful-shot-modal');
        const beautifulShotText = document.getElementById('beautiful-shot-text');
        const lightboxModal = document.getElementById('lightbox-modal');
        const lightboxImage = document.getElementById('lightbox-image');
        const downloadLink = document.getElementById('download-link');
        const closeLightboxBtn = document.getElementById('close-lightbox');

        // --- Event Listeners ---
        imageLoader.addEventListener('change', handleImageUpload);
        correctedCanvas.addEventListener('click', openLightbox);
        closeLightboxBtn.addEventListener('click', closeLightbox);
        lightboxModal.addEventListener('click', (e) => { if (e.target.id === 'lightbox-modal') closeLightbox(); });

        function handleImageUpload(e) {
            // Reset UI state
            originalContainer.classList.add('hidden');
            correctedContainer.classList.add('hidden');
            errorContainer.classList.add('hidden');
            beautifulShotModal.style.display = 'none';
            subjectNameDisplay.textContent = '';
            loaderContainer.classList.remove('hidden');

            const reader = new FileReader();
            reader.onload = function(event) {
                const img = new Image();
                img.onload = async function() {
                    originalImage.src = event.target.result;
                    originalContainer.classList.remove('hidden');
                    
                    try {
                       await processImageWithAI(img);
                    } catch (err) {
                        console.error("Processing failed:", err);
                        showError("An error occurred during AI processing. Please try a different image.");
                        loaderContainer.classList.add('hidden');
                    }
                }
                img.src = event.target.result;
            }
            reader.readAsDataURL(e.target.files[0]);
        }
        
        /**
         * The main pipeline for processing the image with a multi-AI workflow.
         */
        async function processImageWithAI(img) {
            const canvas = document.createElement('canvas');
            canvas.width = img.width;
            canvas.height = img.height;
            const ctx = canvas.getContext('2d', { willReadFrequently: true });
            ctx.drawImage(img, 0, 0);
            
            const base64ImageData = canvas.toDataURL('image/jpeg').split(',')[1];

            // Step 1: Identify the subject with Gemini
            const identificationResponse = await callGeminiAPI(base64ImageData);
            
            subjectNameDisplay.textContent = identificationResponse.subject_name;

            if (!identificationResponse.correction_needed) {
                 beautifulShotText.textContent = `The AI has identified the subject as "${identificationResponse.subject_name}" and determined it already has excellent color balance.`
                 beautifulShotModal.style.display = 'flex';
                 loaderContainer.classList.add('hidden');
                 return;
            }

            // Step 2: Generate a new subject with Imagen 3
            const generatedImageResponse = await callImagenAPI(identificationResponse.subject_name);
            const generatedImage = new Image();
            generatedImage.src = `data:image/png;base64,${generatedImageResponse}`;
            
            await new Promise((resolve, reject) => {
                generatedImage.onload = resolve;
                generatedImage.onerror = reject;
            });


            // Step 3: Composite the images
            await new Promise(resolve => setTimeout(resolve, 50)); // UI update
            
            compositeImages(ctx, generatedImage, identificationResponse.background_water_color_hex);
            
            correctedContainer.classList.remove('hidden');
            loaderContainer.classList.add('hidden');
        }

        /**
         * Calls Gemini API for subject identification.
         */
        async function callGeminiAPI(base64ImageData) {
            const apiKey = ""; // Handled by environment
            const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=${apiKey}`;
            const payload = {
                "contents": [{"parts": [
                    {"text": "You are a marine biologist. Analyze this underwater photo. Respond ONLY with a single JSON object. If it needs correction, the JSON must contain 'correction_needed': true, the 'subject_name' (provide the simplest possible common name, 2 words max, e.g., 'Soft Coral'), and the dominant 'background_water_color_hex'. If not, 'correction_needed': false and the 'subject_name' (simplest common name, 2 words max)."},
                    {"inlineData": { "mimeType": "image/jpeg", "data": base64ImageData }}
                ]}],
                "generationConfig": {"responseMimeType": "application/json", "responseSchema": {
                    "type": "OBJECT", "properties": {
                       "correction_needed": { "type": "BOOLEAN" }, "subject_name": { "type": "STRING" },
                       "background_water_color_hex": { "type": "STRING" }
                    }
                }}
            };
            const response = await fetch(apiUrl, { method: 'POST', headers: { 'Content-Type': 'application/json' }, body: JSON.stringify(payload) });
            if (!response.ok) throw new Error(`Gemini API request failed: ${response.statusText}`);
            const result = await response.json();
            try {
                const text = result.candidates[0].content.parts[0].text;
                return JSON.parse(text.replace(/```json/g, '').replace(/```/g, '').trim());
            } catch (e) {
                console.error("Error parsing Gemini response:", result);
                throw new Error("Could not understand Gemini's response.");
            }
        }

        /**
         * Calls Imagen 3 API to generate a new subject.
         */
        async function callImagenAPI(subjectName) {
            const apiKey = ""; // Handled by environment
            const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/imagen-3.0-generate-002:predict?key=${apiKey}`;
            const payload = {
                instances: [{ 
                    prompt: `Photorealistic, vibrant, high-detail macro shot of a single "${subjectName}", with perfect studio lighting, isolated on a pure black background.`
                }],
                parameters: { "sampleCount": 1 }
            };

            const response = await fetch(apiUrl, { method: 'POST', headers: { 'Content-Type': 'application/json' }, body: JSON.stringify(payload) });
            if (!response.ok) throw new Error(`Imagen API request failed: ${response.statusText}`);
            const result = await response.json();
            
            if (result.predictions && result.predictions.length > 0 && result.predictions[0].bytesBase64Encoded) {
                return result.predictions[0].bytesBase64Encoded;
            } else {
                console.error("Imagen response error", result);
                throw new Error("Failed to generate a new image from the AI.");
            }
        }
        
        /**
         * Creates a soft mask and composites the generated image over the original using luminance matching.
         */
        function compositeImages(ctx, generatedImage, backgroundHex) {
            const originalImageData = ctx.getImageData(0, 0, ctx.canvas.width, ctx.canvas.height);
            const data = originalImageData.data;

            const genCanvas = document.createElement('canvas');
            genCanvas.width = ctx.canvas.width;
            genCanvas.height = ctx.canvas.height;
            const genCtx = genCanvas.getContext('2d', { willReadFrequently: true });
            genCtx.drawImage(generatedImage, 0, 0, genCanvas.width, genCanvas.height);
            const genData = genCtx.getImageData(0, 0, genCanvas.width, genCanvas.height).data;

            const backgroundRgb = hexToRgb(backgroundHex);
            const MASK_SENSITIVITY = 120.0;

            for (let i = 0; i < data.length; i += 4) {
                 const r = data[i], g = data[i+1], b = data[i+2];
                 
                 const distance = Math.sqrt(
                     Math.pow(r - backgroundRgb.r, 2) + Math.pow(g - backgroundRgb.g, 2) + Math.pow(b - backgroundRgb.b, 2)
                 );
                 
                 // Use a smoother S-curve (sigmoid-like) function for a more natural falloff.
                 const maskValue = 1.0 / (1.0 + Math.exp(-(distance - MASK_SENSITIVITY / 1.5) / (MASK_SENSITIVITY / 4)));

                 if (maskValue > 0.01) { // Only process if it's not pure background
                    // Convert original and generated pixels to HSL
                    const originalHsl = rgbToHsl(r, g, b);
                    const genHsl = rgbToHsl(genData[i], genData[i+1], genData[i+2]);

                    // Create the new color by taking the Hue and Saturation from the generated image,
                    // but the Luminance from the ORIGINAL image. This preserves shadows and highlights.
                    const finalHsl = {
                        h: genHsl.h,
                        s: genHsl.s,
                        l: originalHsl.l // KEY: Using original luminance
                    };

                    const correctedRgb = hslToRgb(finalHsl.h, finalHsl.s, finalHsl.l);

                    // Blend the original color and the new luminance-matched color using the soft mask value.
                    data[i]   = r * (1 - maskValue) + correctedRgb.r * maskValue;
                    data[i+1] = g * (1 - maskValue) + correctedRgb.g * maskValue;
                    data[i+2] = b * (1 - maskValue) + correctedRgb.b * maskValue;
                 }
            }
            
            correctedCanvas.width = ctx.canvas.width;
            correctedCanvas.height = ctx.canvas.height;
            correctedCanvas.getContext('2d').putImageData(originalImageData, 0, 0);
        }

        // --- UI Helpers & Utilities ---
        function showError(message) { errorMessage.textContent = message; errorContainer.classList.remove('hidden'); }
        function openLightbox() { lightboxModal.style.display = 'flex'; lightboxImage.src = correctedCanvas.toDataURL('image/png'); downloadLink.href = lightboxImage.src; }
        function closeLightbox() { lightboxModal.style.display = 'none'; }
        function hexToRgb(hex) {
            if (!hex) return {r:0, g:0, b:0};
            const result = /^#?([a-f\d]{2})([a-f\d]{2})([a-f\d]{2})$/i.exec(hex);
            return result ? { r: parseInt(result[1], 16), g: parseInt(result[2], 16), b: parseInt(result[3], 16) } : {r:0, g:0, b:0};
        }
        function rgbToHsl(r, g, b) {
            r /= 255; g /= 255; b /= 255;
            const max = Math.max(r, g, b), min = Math.min(r, g, b);
            let h, s, l = (max + min) / 2;
            if (max == min) { h = s = 0; } else {
                const d = max - min;
                s = l > 0.5 ? d / (2 - max - min) : d / (max + min);
                switch (max) {
                    case r: h = (g - b) / d + (g < b ? 6 : 0); break;
                    case g: h = (b - r) / d + 2; break;
                    case b: h = (r - g) / d + 4; break;
                }
                h /= 6;
            }
            return { h, s, l };
        }
        function hslToRgb(h, s, l) {
            let r, g, b;
            if (s === 0) { r = g = b = l; } else {
                const hue2rgb = (p, q, t) => {
                    if (t < 0) t += 1; if (t > 1) t -= 1;
                    if (t < 1/6) return p + (q - p) * 6 * t;
                    if (t < 1/2) return q;
                    if (t < 2/3) return p + (q - p) * (2/3 - t) * 6;
                    return p;
                };
                const q = l < 0.5 ? l * (1 + s) : l + s - l * s;
                const p = 2 * l - q;
                r = hue2rgb(p, q, h + 1/3);
                g = hue2rgb(p, q, h);
                b = hue2rgb(p, q, h - 1/3);
            }
            return { r: Math.round(r * 255), g: Math.round(g * 255), b: Math.round(b * 255) };
        }
    </script>
</body>
</html>
