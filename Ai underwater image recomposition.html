<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Underwater Image Recomposition</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', sans-serif;
        }
        .custom-file-button input[type="file"] {
            display: none;
        }
        #loader {
            border: 5px solid #f3f3f3;
            border-top: 5px solid #3498db;
            border-radius: 50%;
            width: 50px;
            height: 50px;
            animation: spin 1.5s linear infinite;
        }
        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }
    </style>
</head>
<body class="bg-gray-900 text-gray-200 flex flex-col items-center justify-center min-h-screen p-4">

    <div class="w-full max-w-4xl text-center">
        <header class="mb-8">
            <h1 class="text-4xl md:text-5xl font-bold text-cyan-400 mb-2">AI Underwater Recomposition</h1>
            <p class="text-lg text-gray-400">Replacing the subject with an AI-generated version in its true colors.</p>
        </header>

        <!-- File Upload Section -->
        <div class="bg-gray-800 p-6 rounded-xl shadow-lg w-full mb-8">
            <p class="mb-4">Upload an underwater photo taken with natural light.</p>
            <div class="custom-file-button">
                <label for="imageLoader" class="cursor-pointer bg-cyan-600 hover:bg-cyan-700 text-white font-bold py-3 px-6 rounded-lg transition-colors duration-300 inline-block">
                    Select Image
                </label>
                <input type="file" id="imageLoader" name="imageLoader" accept="image/*"/>
            </div>
        </div>

        <!-- Loading & Identification Indicator -->
        <div id="loader-container" class="hidden flex-col items-center justify-center my-8">
            <div id="loader"></div>
        </div>

        <!-- Image Display Area -->
        <div id="image-container" class="grid grid-cols-1 md:grid-cols-2 gap-8 w-full">
            <div id="original-container" class="hidden text-center">
                <img id="original-image" class="rounded-lg shadow-md w-full" alt="Original underwater photo">
                <p id="subject-name-display" class="text-cyan-400 font-semibold mt-2 text-lg h-8"></p>
            </div>
            <div id="corrected-container" class="hidden">
                <canvas id="corrected-canvas" class="rounded-lg shadow-md w-full cursor-pointer hover:opacity-90 transition-opacity"></canvas>
            </div>
        </div>
        
        <!-- Error Message -->
        <div id="error-container" class="hidden mt-4 bg-red-900 border border-red-700 text-red-200 px-4 py-3 rounded-lg relative" role="alert">
            <strong class="font-bold">Error:</strong>
            <span class="block sm:inline" id="error-message"></span>
        </div>
    </div>

    <!-- "Beautiful Shot" Modal -->
    <div id="beautiful-shot-modal" class="fixed inset-0 bg-black bg-opacity-70 hidden items-center justify-center p-4" onclick="this.style.display='none'">
        <div class="bg-gray-800 rounded-xl p-8 text-center shadow-2xl">
            <h2 class="text-3xl font-bold text-green-400 mb-4">Beautiful Shot!</h2>
            <p id="beautiful-shot-text" class="text-gray-300"></p>
            <p class="mt-4 text-sm text-gray-500">(Click anywhere to close)</p>
        </div>
    </div>

    <!-- Lightbox Modal -->
    <div id="lightbox-modal" class="fixed inset-0 bg-black bg-opacity-80 hidden items-center justify-center p-4 z-50">
        <div class="relative bg-gray-900 p-4 rounded-lg shadow-2xl max-w-4xl w-full max-h-[90vh]">
            <img id="lightbox-image" class="w-full h-full object-contain" alt="Enlarged corrected view">
            <div class="mt-4 flex flex-col sm:flex-row justify-center items-center gap-4">
                <a id="download-link" href="#" download="ai-recomposed-photo.png" class="bg-green-600 hover:bg-green-700 text-white font-bold py-2 px-5 rounded-lg transition-colors duration-300 text-center w-full sm:w-auto">Download</a>
                <button id="close-lightbox" class="bg-red-600 hover:bg-red-700 text-white font-bold py-2 px-5 rounded-lg transition-colors duration-300 w-full sm:w-auto">Close</button>
            </div>
        </div>
    </div>

    <script>
        // --- DOM Elements ---
        const imageLoader = document.getElementById('imageLoader');
        const originalImage = document.getElementById('original-image');
        const correctedCanvas = document.getElementById('corrected-canvas');
        const loaderContainer = document.getElementById('loader-container');
        const originalContainer = document.getElementById('original-container');
        const subjectNameDisplay = document.getElementById('subject-name-display');
        const correctedContainer = document.getElementById('corrected-container');
        const errorContainer = document.getElementById('error-container');
        const errorMessage = document.getElementById('error-message');
        const beautifulShotModal = document.getElementById('beautiful-shot-modal');
        const beautifulShotText = document.getElementById('beautiful-shot-text');
        const lightboxModal = document.getElementById('lightbox-modal');
        const lightboxImage = document.getElementById('lightbox-image');
        const downloadLink = document.getElementById('download-link');
        const closeLightboxBtn = document.getElementById('close-lightbox');

        // --- Event Listeners ---
        imageLoader.addEventListener('change', handleImageUpload);
        correctedCanvas.addEventListener('click', openLightbox);
        closeLightboxBtn.addEventListener('click', closeLightbox);
        lightboxModal.addEventListener('click', (e) => { if (e.target.id === 'lightbox-modal') closeLightbox(); });

        function handleImageUpload(e) {
            // Reset UI state
            originalContainer.classList.add('hidden');
            correctedContainer.classList.add('hidden');
            errorContainer.classList.add('hidden');
            beautifulShotModal.style.display = 'none';
            subjectNameDisplay.textContent = '';
            loaderContainer.classList.remove('hidden');

            const reader = new FileReader();
            reader.onload = function(event) {
                const img = new Image();
                img.onload = async function() {
                    originalImage.src = event.target.result;
                    originalContainer.classList.remove('hidden');
                    
                    try {
                       await processImageWithAI(img);
                    } catch (err) {
                        console.error("Processing failed:", err);
                        showError("An error occurred during AI processing. Please try a different image.");
                        loaderContainer.classList.add('hidden');
                    }
                }
                img.src = event.target.result;
            }
            reader.readAsDataURL(e.target.files[0]);
        }
        
        /**
         * The main pipeline for processing the image with a multi-AI workflow.
         */
        async function processImageWithAI(img) {
            const canvas = document.createElement('canvas');
            canvas.width = img.width;
            canvas.height = img.height;
            const ctx = canvas.getContext('2d', { willReadFrequently: true });
            ctx.drawImage(img, 0, 0);
            
            const base64ImageData = canvas.toDataURL('image/jpeg').split(',')[1];

            // Step 1: Identify the subject with Gemini
            const identificationResponse = await callGeminiAPI(base64ImageData);
            
            subjectNameDisplay.textContent = identificationResponse.subject_name;

            if (!identificationResponse.correction_needed) {
                 beautifulShotText.textContent = `The AI has identified the subject as "${identificationResponse.subject_name}" and determined it already has excellent color balance.`
                 beautifulShotModal.style.display = 'flex';
                 loaderContainer.classList.add('hidden');
                 return;
            }

            // Step 2: Generate a new subject with Imagen 3
            const generatedImageResponse = await callImagenAPI(identificationResponse.subject_name);
            const generatedImage = new Image();
            generatedImage.src = `data:image/png;base64,${generatedImageResponse}`;
            
            await new Promise((resolve, reject) => {
                generatedImage.onload = resolve;
                generatedImage.onerror = reject;
            });


            // Step 3: Composite the images
            await new Promise(resolve => setTimeout(resolve, 50)); // UI update
            
            compositeImages(ctx, generatedImage, identificationResponse.background_water_color_hex);
            
            correctedContainer.classList.remove('hidden');
            loaderContainer.classList.add('hidden');
        }

        /**
         * Calls Gemini API for subject identification.
         */
        async function callGeminiAPI(base64ImageData) {
            const apiKey = ""; // Handled by environment
            const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=${apiKey}`;
            const payload = {
                "contents": [{"parts": [
                    {"text": "You are a marine biologist. Analyze this underwater photo. Respond ONLY with a single JSON object. If it needs correction, the JSON must contain 'correction_needed': true, 'subject_name' (be concise, just the main subject's common name), and the dominant 'background_water_color_hex'. If not, 'correction_needed': false and the 'subject_name' (concise common name)."},
                    {"inlineData": { "mimeType": "image/jpeg", "data": base64ImageData }}
                ]}],
                "generationConfig": {"responseMimeType": "application/json", "responseSchema": {
                    "type": "OBJECT", "properties": {
                       "correction_needed": { "type": "BOOLEAN" }, "subject_name": { "type": "STRING" },
                       "background_water_color_hex": { "type": "STRING" }
                    }
                }}
            };
            const response = await fetch(apiUrl, { method: 'POST', headers: { 'Content-Type': 'application/json' }, body: JSON.stringify(payload) });
            if (!response.ok) throw new Error(`Gemini API request failed: ${response.statusText}`);
            const result = await response.json();
            try {
                const text = result.candidates[0].content.parts[0].text;
                return JSON.parse(text.replace(/```json/g, '').replace(/```/g, '').trim());
            } catch (e) {
                console.error("Error parsing Gemini response:", result);
                throw new Error("Could not understand Gemini's response.");
            }
        }

        /**
         * Calls Imagen 3 API to generate a new subject.
         */
        async function callImagenAPI(subjectName) {
            const apiKey = ""; // Handled by environment
            const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/imagen-3.0-generate-002:predict?key=${apiKey}`;
            const payload = {
                instances: [{ 
                    prompt: `Photorealistic, vibrant, high-detail macro shot of a single "${subjectName}", with perfect studio lighting, isolated on a pure black background.`
                }],
                parameters: { "sampleCount": 1 }
            };

            const response = await fetch(apiUrl, { method: 'POST', headers: { 'Content-Type': 'application/json' }, body: JSON.stringify(payload) });
            if (!response.ok) throw new Error(`Imagen API request failed: ${response.statusText}`);
            const result = await response.json();
            
            if (result.predictions && result.predictions.length > 0 && result.predictions[0].bytesBase64Encoded) {
                return result.predictions[0].bytesBase64Encoded;
            } else {
                console.error("Imagen response error", result);
                throw new Error("Failed to generate a new image from the AI.");
            }
        }
        
        /**
         * Creates a soft mask and composites the generated image over the original.
         */
        function compositeImages(ctx, generatedImage, backgroundHex) {
            const originalImageData = ctx.getImageData(0, 0, ctx.canvas.width, ctx.canvas.height);
            const data = originalImageData.data;

            // Draw the generated image onto a temporary canvas to get its pixel data
            const genCanvas = document.createElement('canvas');
            genCanvas.width = ctx.canvas.width;
            genCanvas.height = ctx.canvas.height;
            const genCtx = genCanvas.getContext('2d', { 
